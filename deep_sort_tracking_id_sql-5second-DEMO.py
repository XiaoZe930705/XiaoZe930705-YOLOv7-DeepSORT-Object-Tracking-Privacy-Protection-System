import argparse
import time
from pathlib import Path
import os
import cv2
import torch
import torch.backends.cudnn as cudnn
from numpy import random
import numpy as np
from models.experimental import attempt_load
from utils.datasets import LoadStreams, LoadImages
from utils.general import (check_img_size, check_imshow, non_max_suppression,
                           scale_coords, xyxy2xywh, strip_optimizer, set_logging,
                           increment_path)
from utils.plots import plot_one_box
from utils.torch_utils import select_device, load_classifier, time_synchronized, TracedModel
from deep_sort_pytorch.utils.parser import get_config
from deep_sort_pytorch.deep_sort import DeepSort
from collections import defaultdict
import pyodbc
from datetime import datetime, timedelta
import requests
from PIL import Image, ImageDraw, ImageFont

# ----------------------------- å…¨åŸŸè®Šæ•¸å€ -----------------------------
location_id = None
spatial_density = 0
limit_the_number_of_people = 0
congestion_threshold = 0
near_congestion_threshold = 0
comfort_threshold = 0
normal_threshold = 0

# Line Notify é…ç½®
access_token = 'OQftvj6sWK7m2n1BD0fAmMPV5YGyTJsmoysrxejwzbh'  # è«‹æ›¿æ›ç‚ºæ‚¨çš„å­˜å–æ¬Šæ–
dashboard_url = "http://127.0.0.1:3000/d/fe18lsbehefpce/..."

# SQL Server é€£æ¥è¨­å®š
conn_str = (
    r'DRIVER={SQL Server};'
    r'SERVER=127.0.0.1;'
    r'DATABASE=researchdata;'
    r'UID=La208;'
    r'PWD=La208-2+'
)

# å»ºç«‹è³‡æ–™åº«é€£æ¥
conn = pyodbc.connect(conn_str)
cursor = conn.cursor()

# é¡è‰²è¨­å®š
palette = (2 ** 11 - 1, 2 ** 15 - 1, 2 ** 20 - 1)
data_deque = {}
pts = defaultdict(list)

# ----------------------------- å‡½æ•¸å€ -----------------------------
def send_line_notify(message, token):
    """
    ç™¼é€æ¶ˆæ¯è‡³ Line Notify
    :param message: è¦ç™¼é€çš„æ¶ˆæ¯å…§å®¹
    :param token: Line Notify çš„å­˜å–æ¬Šæ–
    """
    url = "https://notify-api.line.me/api/notify"
    headers = {
        "Authorization": f"Bearer {token}"
    }
    data = {
        "message": message
    }
    try:
        response = requests.post(url, headers=headers, data=data)
        response.raise_for_status()
        return response.status_code, response.text
    except requests.exceptions.RequestException as e:
        return None, str(e)

def get_location_info(location_id):
    query = """
    SELECT LocationName, Area
    FROM Location
    WHERE LocationID = ?
    """
    cursor.execute(query, (location_id,))
    result = cursor.fetchone()
    if result:
        return result.LocationName, result.Area
    else:
        return None, None

def create_person(detection_id):
    insert_query = """
    INSERT INTO Person (DetectionID)
    VALUES (?)
    """
    cursor.execute(insert_query, (detection_id,))
    conn.commit()
    cursor.execute("SELECT @@IDENTITY AS ID")
    return cursor.fetchone()[0]

def insert_stay_record(person_id, location_id, arrival_time, departure_time, duration):
    if person_id is None or location_id is None:
        print(f"è­¦å‘Šï¼šç”±æ–¼å­˜åœ¨ç©ºå€¼ï¼Œè·³éåœç•™è¨˜éŒ„æ’å…¥ã€‚PersonID: {person_id}, LocationID: {location_id}")
        return
    query = """
    INSERT INTO StayRecord (PersonID, LocationID, ArrivalTime, DepartureTime, Duration)
    VALUES (?, ?, ?, ?, ?)
    """
    duration_str = format(duration, '.10f').rstrip('0').rstrip('.')
    cursor.execute(query, (person_id, location_id, arrival_time, departure_time, duration_str))
    conn.commit()

def insert_traffic_stats(location_id, start_time, end_time, person_count, average_duration, occupancy_rate):
    if location_id is None:
        print(f"è­¦å‘Šï¼šç”±æ–¼å­˜åœ¨ç©ºå€¼ï¼Œè·³é TrafficStats æ’å…¥ã€‚LocationID: {location_id}")
        return
    query = """
    INSERT INTO TrafficStats (LocationID, StartTime, EndTime, PersonCount, AverageDuration, OccupancyRate)
    VALUES (?, ?, ?, ?, ?, ?)
    """
    average_duration_str = format(average_duration, '.10f').rstrip('0').rstrip('.')
    cursor.execute(query, (location_id, start_time, end_time, person_count, average_duration_str, occupancy_rate))
    conn.commit()

def insert_congestion_record(location_id, start_time, end_time, average_occupancy_rate):
    if location_id is None:
        print(f"è­¦å‘Šï¼šç”±æ–¼å­˜åœ¨ç©ºå€¼ï¼Œè·³é CongestionRecord æ’å…¥ã€‚LocationID: {location_id}")
        return
    query = """
    INSERT INTO CongestionRecord (LocationID, StartTime, EndTime, AverageOccupancyRate)
    VALUES (?, ?, ?, ?)
    """
    cursor.execute(query, (location_id, start_time, end_time, average_occupancy_rate))
    conn.commit()

def insert_comfort_record(location_id, start_time, end_time, average_occupancy_rate):
    if location_id is None:
        print(f"è­¦å‘Šï¼šç”±æ–¼å­˜åœ¨ç©ºå€¼ï¼Œè·³é ComfortRecord æ’å…¥ã€‚LocationID: {location_id}")
        return
    query = """
    INSERT INTO ComfortRecord (LocationID, StartTime, EndTime, AverageOccupancyRate)
    VALUES (?, ?, ?, ?)
    """
    cursor.execute(query, (location_id, start_time, end_time, average_occupancy_rate))
    conn.commit()

def compute_color_for_labels(label):
    """
    ç°¡å–®å‡½æ•¸ï¼Œæ ¹æ“šé¡åˆ¥å›ºå®šç”Ÿæˆé¡è‰²ã€‚
    """
    color = [int((p * (label ** 2 - label + 1)) % 255) for p in palette]
    return tuple(color)

def draw_boxes(img, bbox, names, identities=None, active_objects=None, offset=(0, 0)):
    """
    ç¹ªè£½æª¢æ¸¬æ¡†ã€æ¨¡ç³Šæ¡†å…§å…§å®¹ï¼Œä»¥åŠåœ¨æ¯å€‹æ¡†çš„å³ä¸Šè§’é¡¯ç¤º ID å’Œæ»¯ç•™æ™‚é–“ã€‚
    """
    height, width, _ = img.shape
    text_info = []  # å„²å­˜æ¯å€‹æ¡†çš„æ–‡å­—åŠå…¶ä½ç½®

    for i, box in enumerate(bbox):
        x1, y1, x2, y2 = [int(coord) for coord in box]
        x1 += offset[0]
        x2 += offset[0]
        y1 += offset[1]
        y2 += offset[1]

        # ç¢ºä¿åº§æ¨™åœ¨åœ–åƒç¯„åœå…§
        x1 = max(0, x1)
        y1 = max(0, y1)
        x2 = min(x2, img.shape[1])
        y2 = min(y2, img.shape[0])

        # å°äººçš„é‚Šç•Œæ¡†å…§å®¹é€²è¡Œæ¨¡ç³Š
        person_roi = img[y1:y2, x1:x2]
        person_roi = cv2.GaussianBlur(person_roi, (99, 99), 30)
        img[y1:y2, x1:x2] = person_roi

        # ç¹ªè£½æª¢æ¸¬æ¡†
        color = (255, 0, 0)
        if identities is not None:
            color = compute_color_for_labels(int(identities[i]))
        cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)

        # æ”¶é›†æ–‡å­—ä¿¡æ¯åŠå…¶ä½ç½®
        if identities is not None:
            identity = int(identities[i])
            if active_objects and identity in active_objects:
                arrival_time = active_objects[identity]['arrival_time']
                duration = datetime.now() - arrival_time
                duration_minutes = round(duration.total_seconds() / 60.0, 2)
            else:
                duration_minutes = 0.0
            text = f"ID: {identity}, æ»¯ç•™: {duration_minutes} min"
            text_position = (x2, y1)  # æ¡†çš„å³ä¸Šè§’
            text_info.append((text, text_position, color))

    # ä½¿ç”¨ PIL ä¾†ç¹ªè£½ä¸­æ–‡æ–‡å­—
    im_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(im_pil)

    font_path = "C:/Windows/Fonts/simsun.ttc"
    try:
        font = ImageFont.truetype(font_path, 20)
    except IOError:
        print(f"å­—é«”æ–‡ä»¶ {font_path} ä¸å­˜åœ¨ã€‚è«‹ç¢ºä¿å­—é«”æ–‡ä»¶å­˜åœ¨æˆ–æ›´æ”¹ font_path ç‚ºæœ‰æ•ˆè·¯å¾‘ã€‚")
        font = ImageFont.load_default()

    for text, position, color in text_info:
        text_bbox = font.getbbox(text)
        text_width = text_bbox[2] - text_bbox[0]
        text_height = text_bbox[3] - text_bbox[1]
        x, y = position
        if x + text_width > width:
            x = width - text_width
        if y - text_height < 0:
            y = text_height
        draw.text((x, y - text_height), text, font=font, fill=(255, 255, 255))

    # è½‰å› OpenCV åœ–åƒ
    img = cv2.cvtColor(np.array(im_pil), cv2.COLOR_RGB2BGR)
    return img

def detect(save_img=False):
    global location_id, spatial_density, limit_the_number_of_people
    global congestion_threshold, frame_count, fps, location_name

    source = opt.source
    weights = opt.weights
    view_img = opt.view_img
    save_txt = opt.save_txt
    imgsz = opt.img_size
    trace = not opt.no_trace

    save_img = not opt.nosave and not str(source).endswith('.txt')

    # åˆå§‹åŒ–ä¸€äº›è®Šæ•¸
    person_count = 0

    # ç›®éŒ„
    save_dir = Path(increment_path(Path(opt.project) / opt.name, exist_ok=opt.exist_ok))
    (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)

    # è¨­ç½® FFMPEG ä½å»¶é²é¸é … (è‹¥ä½¿ç”¨æœ¬æ©Ÿæ”å½±æ©Ÿï¼Œé€™ä¸å½±éŸ¿ï¼Œå¯ä¿ç•™æˆ–ç§»é™¤)
    os.environ["OPENCV_FFMPEG_CAPTURE_OPTIONS"] = "rtsp_transport;udp"

    # åˆå§‹åŒ–
    set_logging()
    device = select_device(opt.device)
    half = device.type != 'cpu'

    # åŠ è¼‰æ¨¡å‹
    model = attempt_load(weights, map_location=device)
    stride = int(model.stride.max())
    imgsz = check_img_size(imgsz, s=stride)

    # è‹¥éœ€è¦ trace model
    if trace:
        model = TracedModel(model, device, opt.img_size)

    if half:
        model.half()

    # ä¸åšåˆ†é¡
    classify = False

    vid_path, vid_writer = None, None
    view_img = check_imshow()
    cudnn.benchmark = True

    # å¦‚æœ source æ˜¯ intï¼Œä»£è¡¨ä½¿ç”¨æœ¬æ©Ÿæ”å½±æ©Ÿ
    dataset = LoadStreams(source, img_size=imgsz, stride=stride)

    names = model.module.names if hasattr(model, 'module') else model.names

    if device.type != 'cpu':
        model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))

    old_img_w = old_img_h = imgsz
    old_img_b = 1

    t0 = time.time()

    # ----------------- deep_sort åˆå§‹åŒ– -----------------
    cfg_deep = get_config()
    cfg_deep.merge_from_file("deep_sort_pytorch/configs/deep_sort.yaml")
    deepsort = DeepSort(
        cfg_deep.DEEPSORT.REID_CKPT,
        max_dist=0.7,
        min_confidence=0.3,
        nms_max_overlap=cfg_deep.DEEPSORT.NMS_MAX_OVERLAP,
        max_iou_distance=0.7,
        max_age=50,
        n_init=3,
        nn_budget=cfg_deep.DEEPSORT.NN_BUDGET,
        use_cuda=(device.type != 'cpu')
    )

    frame_count = 0
    fps = 30

    # åŸæœ¬è¨­å®šç‚º 5 ç§’
    last_insert_time_5s_datetime = datetime.now()
    interval_departed_objects = []
    active_objects = {}
    max_age = deepsort.tracker.max_age
    video_writers = {}
    last_congestion_status = None
    last_congestion_notification_time = datetime.min
    congestion_notification_interval = timedelta(minutes=5)
    overstay_duration_threshold = timedelta(minutes=30)

    # ----------------- é–‹å§‹è®€å–å½±åƒæµ -----------------
    for path, img, im0s, vid_cap in dataset:
        start_time = time.time()

        # å–å¾— FPS (è‹¥ç‚ºæœ¬æ©Ÿæ”å½±æ©Ÿï¼Œå‰‡å¯å¾ vid_cap å–å¾—)
        if vid_cap:
            fps = vid_cap.get(cv2.CAP_PROP_FPS)
            if fps == 0 or fps is None:
                fps = 24
        else:
            fps = 24

        # æ¯å¹€é‡æ–°åˆå§‹åŒ– person_count
        person_count = 0

        img = torch.from_numpy(img).to(device)
        img = img.half() if half else img.float()
        img /= 255.0
        if img.ndimension() == 3:
            img = img.unsqueeze(0)

        # é ç†±
        if device.type != 'cpu':
            if (old_img_b != img.shape[0] or 
                old_img_h != img.shape[2] or 
                old_img_w != img.shape[3]):
                old_img_b = img.shape[0]
                old_img_h = img.shape[2]
                old_img_w = img.shape[3]
                for _ in range(3):
                    model(img, augment=opt.augment)[0]

        t1 = time_synchronized()
        with torch.no_grad():
            pred = model(img, augment=opt.augment)[0]
        t2 = time_synchronized()

        # é€²è¡Œ NMS
        pred = non_max_suppression(pred, opt.conf_thres, opt.iou_thres, 
                                   classes=opt.classes, agnostic=opt.agnostic_nms)
        t3 = time_synchronized()

        inference_time = t2 - t1
        nms_time = t3 - t2

        for i, det in enumerate(pred):
            p, s, im0, frame = dataset.sources[i], f'{i}: ', im0s[i].copy(), dataset.count
            p = Path(p)

            # å»ºç«‹ VideoWriter
            if save_img:
                if p not in video_writers:
                    width = im0.shape[1]
                    height = im0.shape[0]
                    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
                    output_path = save_dir / f"{p.stem}_{i}.mp4"
                    video_writers[p] = cv2.VideoWriter(str(output_path), fourcc, fps, (width, height))
                    print(f"åˆå§‹åŒ– VideoWriterï¼Œè¼¸å‡ºè·¯å¾‘ï¼š{output_path}")

            if det is not None and len(det):
                det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()

                # æ‰“å°æª¢æ¸¬çµæœ
                for c in det[:, -1].unique():
                    n = (det[:, -1] == c).sum()
                    s += f"{n} {names[int(c)]}{'s' * (n > 1)}, "

                xywhs = xyxy2xywh(det[:, 0:4])
                confs = det[:, 4]
                clss = det[:, 5]

                # æ›´æ–° deep sort
                outputs = deepsort.update(xywhs.cpu(), confs.cpu(), clss.cpu(), im0)

                current_ids = set()
                for track in deepsort.tracker.tracks:
                    if not track.is_confirmed():
                        continue
                    id_ = track.track_id
                    current_ids.add(id_)
                    if id_ not in active_objects:
                        person_id = create_person(int(id_))
                        arrival_time = datetime.now()
                        active_objects[id_] = {
                            'arrival_time': arrival_time,
                            'person_id': person_id,
                            'missing_frames': 0,
                            'notified_over_30': False
                        }
                    else:
                        active_objects[id_]['missing_frames'] = 0

                # æ‰¾å‡ºæ¶ˆå¤±ç›®æ¨™
                ids_to_remove = []
                for id_ in list(active_objects.keys()):
                    if id_ not in current_ids:
                        active_objects[id_]['missing_frames'] += 1
                        if active_objects[id_]['missing_frames'] >= max_age:
                            data = active_objects[id_]
                            departure_time = datetime.now()
                            duration_timedelta = departure_time - data['arrival_time']
                            duration_minutes = duration_timedelta.total_seconds() / 60.0
                            person_id = data['person_id']
                            arrival_time = data['arrival_time']

                            insert_stay_record(person_id, location_id, arrival_time, departure_time, duration_minutes)
                            interval_departed_objects.append({
                                'duration': duration_minutes,
                                'person_id': person_id
                            })
                            ids_to_remove.append(id_)

                for id_ in ids_to_remove:
                    del active_objects[id_]

                if len(outputs) > 0:
                    bbox_xyxy = outputs[:, :4]
                    identities = outputs[:, 4]
                    im0 = draw_boxes(im0, bbox_xyxy, names, identities, active_objects)

            # æ›´æ–° person_count
            person_count = len(active_objects)

            # è¨ˆç®—ä½”ç”¨ç‡
            occupancy_rate = 0
            if spatial_density * limit_the_number_of_people != 0:
                occupancy_rate = (person_count / (spatial_density * limit_the_number_of_people)) * 100
            occupancy_rate = min(round(occupancy_rate, 2), 100)

            # ç‹€æ…‹èˆ‡é¡è‰²åˆ¤å®š
            if occupancy_rate >= 100:
                status = "å£…å¡"
                status_color = (0, 0, 255)
            elif occupancy_rate >= 80:
                status = "å³å°‡å£…å¡"
                status_color = (0, 165, 255)
            elif occupancy_rate >= 60:
                status = "æ­£å¸¸"
                status_color = (0, 255, 0)
            else:
                status = "èˆ’é©"
                status_color = (255, 0, 0)

            end_time = time.time()
            total_time = end_time - start_time
            fps_display = 1 / total_time if total_time > 0 else 0

            print(f"Inference Time: {inference_time*1000:.1f} ms, "
                  f"NMS Time: {nms_time*1000:.1f} ms, "
                  f"FPS: {fps_display:.1f}")
            print(f"Person Count: {person_count}")

            # ä½¿ç”¨ PIL ä¾†ç¹ªè£½ä¸­æ–‡æ–‡å­—
            im_pil = Image.fromarray(cv2.cvtColor(im0, cv2.COLOR_BGR2RGB))
            draw_pil = ImageDraw.Draw(im_pil)

            font_path = "C:/Windows/Fonts/simsun.ttc"
            try:
                font_status = ImageFont.truetype(font_path, 30)
                font_count = ImageFont.truetype(font_path, 30)
            except IOError:
                print(f"å­—é«”æ–‡ä»¶ {font_path} ä¸å­˜åœ¨ã€‚")
                font_status = ImageFont.load_default()
                font_count = ImageFont.load_default()

            status_color_rgb = (status_color[2], status_color[1], status_color[0])
            white_color_rgb = (255, 255, 255)

            draw_pil.text((10, 10), f"ç‹€æ…‹: {status}", font=font_status, fill=status_color_rgb)
            draw_pil.text((10, 50), f"äººæ•¸: {person_count}", font=font_count, fill=white_color_rgb)

            im0 = cv2.cvtColor(np.array(im_pil), cv2.COLOR_RGB2BGR)

            if save_img and p in video_writers:
                video_writers[p].write(im0)

            # æ¯ 5 ç§’å¯«å…¥ä¸€æ¬¡è³‡æ–™åº«
            if (datetime.now() - last_insert_time_5s_datetime) >= timedelta(seconds=5):
                current_time = datetime.now()
                start_time_db = last_insert_time_5s_datetime
                end_time_db = current_time

                total_duration = sum(obj['duration'] for obj in interval_departed_objects)
                total_person_count = len(interval_departed_objects)
                if total_person_count > 0:
                    average_duration = total_duration / total_person_count
                else:
                    average_duration = 0

                # é‡æ–°è¨ˆç®—æœ€æ–°çš„ä½”ç”¨ç‡
                occupancy_rate = 0
                if spatial_density * limit_the_number_of_people != 0:
                    occupancy_rate = (person_count / (spatial_density * limit_the_number_of_people)) * 100
                occupancy_rate = min(round(occupancy_rate, 2), 100)

                # å¯«å…¥è³‡æ–™åº«
                insert_traffic_stats(location_id, start_time_db, end_time_db, 
                                     person_count, average_duration, occupancy_rate)

                if occupancy_rate >= 100:
                    insert_congestion_record(location_id, start_time_db, end_time_db, occupancy_rate)
                if occupancy_rate < 60:
                    insert_comfort_record(location_id, start_time_db, end_time_db, occupancy_rate)

                interval_departed_objects.clear()
                last_insert_time_5s_datetime = current_time

            # è‹¥é”åˆ°å£…å¡æˆ–å³å°‡å£…å¡æ™‚ï¼Œç™¼é€ Line é€šçŸ¥
            current_time = datetime.now()
            if status in ["å³å°‡å£…å¡", "å£…å¡"]:
                if (status != last_congestion_status) or (
                    current_time - last_congestion_notification_time > congestion_notification_interval
                ):
                    message = (
                        "\n\n"
                        f"âš ï¸ è­¦ç¤ºé€šçŸ¥ï¼š{location_name}ç¾å ´äººæ•¸é”åˆ°{status}ç‹€æ…‹ï¼ âš ï¸\n\n"
                        "ğŸ“Š ç¾æ³ï¼š\n"
                        f"- ç•¶å‰äººæ•¸ï¼š{person_count}äºº\n"
                        f"- å»ºè­°å®¹ç´äººæ•¸ï¼š{int(congestion_threshold)}äºº\n\n"
                        "ğŸ› ï¸ è«‹ç«‹å³æ¡å–ä»¥ä¸‹æªæ–½ï¼š(...ç°¡åŒ–...)"
                        f"\nğŸ”— æŸ¥çœ‹å„€è¡¨æ¿è©³æƒ…ï¼š{dashboard_url}"
                    )
                    status_code, response_text = send_line_notify(message, access_token)
                    if status_code == 200:
                        print(f"å·²ç™¼é€{status}ç‹€æ…‹é€šçŸ¥")
                        last_congestion_status = status
                        last_congestion_notification_time = current_time
                    else:
                        print(f"ç™¼é€é€šçŸ¥å¤±æ•—: {response_text}")

            # æ»¯ç•™è¶…é30åˆ†é˜é€šçŸ¥
            for id_ in active_objects:
                data = active_objects[id_]
                duration = current_time - data['arrival_time']
                if duration >= overstay_duration_threshold:
                    if not data.get('notified_over_30', False):
                        message = (
                            "\n\n"
                            f"âš ï¸ æ»¯ç•™é€šçŸ¥ï¼šIDç‚º {id_} çš„äººå“¡å·²åœ¨ {location_name} æ»¯ç•™è¶…é30åˆ†é˜ï¼ âš ï¸\n\n"
                            "ğŸ› ï¸ è«‹ç«‹å³æ¡å–ä»¥ä¸‹æªæ–½ï¼š(...ç°¡åŒ–...)"
                            f"\nğŸ”— æŸ¥çœ‹å„€è¡¨æ¿è©³æƒ…ï¼š{dashboard_url}"
                        )
                        status_code, response_text = send_line_notify(message, access_token)
                        if status_code == 200:
                            print(f"å·²ç™¼é€ID {id_} çš„æ»¯ç•™é€šçŸ¥")
                            data['notified_over_30'] = True
                        else:
                            print(f"ç™¼é€é€šçŸ¥å¤±æ•—: {response_text}")

        # å¦‚æœè¦é¡¯ç¤ºç•«é¢ï¼ˆå…è¨±ç”¨æ»‘é¼ è‡ªç”±æ‹–æ›³è¦–çª—å¤§å°ï¼‰
        if view_img:
            window_name = f"Stream {i}"
            # å»ºç«‹å¯ç¸®æ”¾è¦–çª—
            cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
            # å¯ä»¥è¨­å®šåˆå§‹å¤§å°ï¼Œè‹¥æƒ³è®“å…¶è‡ªå‹•èª¿æ•´ä¹Ÿå¯çœç•¥é€™è¡Œ
            cv2.resizeWindow(window_name, 1540, 1280)
            # ç›´æ¥é¡¯ç¤ºåŸå½±åƒ
            cv2.imshow(window_name, im0)
            cv2.waitKey(1)

        frame_count += 1

    print(f'å®Œæˆã€‚ ({time.time() - t0:.3f} ç§’)')

    # é‡‹æ”¾ VideoWriter
    if save_img:
        for writer in video_writers.values():
            writer.release()

# ----------------------------- ä¸»ç¨‹å¼å…¥å£ -----------------------------
if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--weights', nargs='+', type=str, default='yolov7.pt', help='æ¨¡å‹è·¯å¾‘')
    parser.add_argument('--source', type=str, default='0', help='ä¾†æºï¼Œé è¨­ç‚º0(æœ¬æ©Ÿæ”å½±æ©Ÿ)æˆ–å¯æ”¾æª”æ¡ˆè·¯å¾‘ã€RTSP')
    parser.add_argument('--img-size', type=int, default=480, help='æ¨è«–åœ–åƒå¤§å°ï¼ˆåƒç´ ï¼‰')
    parser.add_argument('--conf-thres', type=float, default=0.25, help='ç‰©é«”ç½®ä¿¡é–€æª»')
    parser.add_argument('--iou-thres', type=float, default=0.45, help='NMS çš„ IOU é–€æª»')
    parser.add_argument('--device', default='0', help='cuda è¨­å‚™ï¼Œä¾‹å¦‚ 0 æˆ– 0,1,2,3 æˆ– cpu')
    parser.add_argument('--view-img', action='store_true', help='é¡¯ç¤ºçµæœ')
    parser.add_argument('--save-txt', action='store_true', help='å°‡çµæœä¿å­˜ç‚º *.txt')
    parser.add_argument('--save-conf', action='store_true', help='ä¿å­˜ç½®ä¿¡åº¦æ–¼ --save-txt æ¨™ç±¤')
    parser.add_argument('--nosave', action='store_true', help='ä¸ä¿å­˜åœ–åƒ/è¦–é »')
    parser.add_argument('--classes', nargs='+', type=int, default=[0], help='æŒ‰é¡åˆ¥ç¯©é¸ï¼š--class 0, æˆ– --class 0 2 3')
    parser.add_argument('--agnostic-nms', action='store_true', help='é¡åˆ¥ç„¡é—œçš„ NMS')
    parser.add_argument('--augment', action='store_true', help='å¢å¼·æ¨è«–')
    parser.add_argument('--update', action='store_true', help='æ›´æ–°æ‰€æœ‰æ¨¡å‹')
    parser.add_argument('--project', default='runs/detect', help='ä¿å­˜çµæœè‡³é …ç›®/åç¨±')
    parser.add_argument('--name', default='exp', help='ä¿å­˜çµæœè‡³é …ç›®/åç¨±')
    parser.add_argument('--exist-ok', action='store_true', help='å…è¨±å·²æœ‰çš„é …ç›®/åç¨±ï¼Œä¸éå¢')
    parser.add_argument('--no-trace', action='store_true', help='ä¸è¿½è¹¤æ¨¡å‹')
    opt = parser.parse_args()
    print(opt)

    # è®“ä½¿ç”¨è€…é¸æ“‡ä½ç½® (å‡è¨­é‚„éœ€è¦åšä½ç½®é¸æ“‡é‚è¼¯)
    print("è«‹é¸æ“‡ä¸€å€‹ä½ç½®ï¼š")
    print("-----------")
    print("1. é†«é™¢å¤§å»³å·¦åŠéƒ¨")
    print("2. é†«é™¢å¤§å»³å³åŠéƒ¨")
    print("3. é†«é™¢å’–å•¡å»³ A å€")
    print("4. Mlab-Test-1")
    print("5. Mlab-Test-2")
    print("-----------")

    while True:
        try:
            location_choice = int(input("è«‹è¼¸å…¥ä½ç½®ç·¨è™Ÿ (1-5): "))
            if 1 <= location_choice <= 5:
                location_id = location_choice
                break
            else:
                print("è«‹è¼¸å…¥æœ‰æ•ˆçš„ä½ç½®ç·¨è™Ÿ (1-5)ã€‚")
        except ValueError:
            print("è«‹è¼¸å…¥æœ‰æ•ˆçš„æ•¸å­—ã€‚")

    location_name, spatial_density = get_location_info(location_id)
    print(f"å·²é¸æ“‡ä½ç½®ï¼š{location_name}ï¼Œç©ºé–“å¤§å°ï¼š{spatial_density} å¹³æ–¹å…¬å°º")

    print("-----------")

    # æ˜¯å¦è®Šæ›´æ¯å¹³æ–¹ç±³å®¹ç´äººæ•¸åƒæ•¸
    question = str(input("è«‹å•æ˜¯å¦éœ€è¦è®Šæ›´æ¯å¹³æ–¹ç±³å®¹ç´äººæ•¸åƒæ•¸(éœ€è¦è®Šæ›´è«‹è¼¸å…¥1ï¼Œç„¡é ˆè®Šæ›´è«‹è¼¸å…¥0):"))
    while True:
        if question == '1':
            while True:
                try:
                    limit_the_number_of_people = int(input("è«‹è¼¸å…¥æ¯å¹³æ–¹ç±³å®¹ç´äººæ•¸(é»˜èªå€¼ç‚º:3):"))
                    if limit_the_number_of_people > 0:
                        break
                    else:
                        print("è«‹å‹¿è¼¸å…¥ç„¡æ•ˆåƒæ•¸!!")
                except ValueError:
                    print("æ‚¨è¼¸å…¥çš„ä¸æ˜¯æœ‰æ•ˆçš„æ•¸å­—ï¼Œè«‹é‡æ–°è¼¸å…¥ã€‚")
            break
        elif question == '0':
            limit_the_number_of_people = 3
            break
        else:
            print("è«‹è¼¸å…¥æ­£ç¢ºæ•¸å€¼")
            question = str(input("è«‹å•æ˜¯å¦éœ€è¦è®Šæ›´æ¯å¹³æ–¹ç±³å®¹ç´äººæ•¸åƒæ•¸(éœ€è¦è®Šæ›´è«‹è¼¸å…¥1ï¼Œç„¡é ˆè®Šæ›´è«‹è¼¸å…¥0):"))

    congestion_threshold = spatial_density * limit_the_number_of_people
    comfort_threshold = round(congestion_threshold * 0.4, 3)
    normal_threshold = round(congestion_threshold * 0.6, 3)
    near_congestion_threshold = round(congestion_threshold * 0.8, 3)

    print(f"äººæµå£…å¡ç•Œé™: {congestion_threshold}")
    print(f"å³å°‡å£…å¡ç•Œé™: {near_congestion_threshold}")
    print(f"äººæµèˆ’é©ç•Œé™: {comfort_threshold}")
    print(f"äººæµæ­£å¸¸ç•Œé™: {normal_threshold}")
    print("-----------")

    with torch.no_grad():
        if opt.update:
            for w in ['yolov7.pt']:
                detect()
                strip_optimizer(w)
        else:
            detect()
