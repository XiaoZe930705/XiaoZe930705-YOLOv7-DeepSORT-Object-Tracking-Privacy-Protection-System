import argparse
import time
from pathlib import Path
import os
import cv2
import torch
import torch.backends.cudnn as cudnn
from numpy import random
import numpy as np
from models.experimental import attempt_load
from utils.datasets import LoadStreams, LoadImages
from utils.general import (check_img_size, check_requirements, check_imshow, non_max_suppression,
                           apply_classifier, scale_coords, xyxy2xywh, strip_optimizer, set_logging,
                           increment_path, check_file)
from utils.plots import plot_one_box
from utils.torch_utils import select_device, load_classifier, time_synchronized, TracedModel
from deep_sort_pytorch.utils.parser import get_config
from deep_sort_pytorch.deep_sort import DeepSort
from collections import deque, defaultdict
import pyodbc
from datetime import datetime, timedelta
import requests
from PIL import Image, ImageDraw, ImageFont  # æ–°å¢

# å…¨åŸŸè®Šæ•¸
location_id = None
spatial_density = 0
limit_the_number_of_people = 0
congestion_threshold = 0
near_congestion_threshold = 0
comfort_threshold = 0
normal_threshold = 0

# Line Notify é…ç½®
access_token = 'OQftvj6sWK7m2n1BD0fAmMPV5YGyTJsmoysrxejwzbh'  # è«‹æ›¿æ›ç‚ºæ‚¨çš„å­˜å–æ¬Šæ–
dashboard_url = "http://127.0.0.1:3000/d/fe18lsbehefpce/18d6023f-901b-59bd-aff1-a26fd9ceed32?orgId=1&showCategory=Panel+options&from=1732941598588&to=1732942198588"

# SQL Server é€£æ¥è¨­å®š
conn_str = (
    r'DRIVER={SQL Server};'
    r'SERVER=127.0.0.1;'
    r'DATABASE=researchdata;'
    r'UID=La208;'
    r'PWD=La208-2+'
)

# å»ºç«‹è³‡æ–™åº«é€£æ¥
conn = pyodbc.connect(conn_str)
cursor = conn.cursor()

# é¡è‰²è¨­å®š
palette = (2 ** 11 - 1, 2 ** 15 - 1, 2 ** 20 - 1)
data_deque = {}
pts = defaultdict(list)

def send_line_notify(message, token):
    """
    ç™¼é€æ¶ˆæ¯è‡³ Line Notify
    :param message: è¦ç™¼é€çš„æ¶ˆæ¯å…§å®¹
    :param token: Line Notify çš„å­˜å–æ¬Šæ–
    """
    url = "https://notify-api.line.me/api/notify"
    headers = {
        "Authorization": f"Bearer {token}"
    }
    data = {
        "message": message
    }
    try:
        response = requests.post(url, headers=headers, data=data)
        response.raise_for_status()
        return response.status_code, response.text
    except requests.exceptions.RequestException as e:
        return None, str(e)

def xyxy_to_xywh(*xyxy):
    """è¨ˆç®—ç›¸å°æ–¼åƒç´ å€¼çš„é‚Šç•Œæ¡†ã€‚"""
    bbox_left = min([xyxy[0].item(), xyxy[2].item()])
    bbox_top = min([xyxy[1].item(), xyxy[3].item()])
    bbox_w = abs(xyxy[0].item() - xyxy[2].item())
    bbox_h = abs(xyxy[1].item() - xyxy[3].item())
    x_c = (bbox_left + bbox_w / 2)
    y_c = (bbox_top + bbox_h / 2)
    w = bbox_w
    h = bbox_h
    return x_c, y_c, w, h

def get_location_info(location_id):
    query = """
    SELECT LocationName, Area
    FROM Location
    WHERE LocationID = ?
    """
    cursor.execute(query, (location_id,))
    result = cursor.fetchone()
    if result:
        return result.LocationName, result.Area
    else:
        return None, None

def create_person(detection_id):
    insert_query = """
    INSERT INTO Person (DetectionID)
    VALUES (?)
    """
    cursor.execute(insert_query, (detection_id,))
    conn.commit()
    cursor.execute("SELECT @@IDENTITY AS ID")
    return cursor.fetchone()[0]

def insert_stay_record(person_id, location_id, arrival_time, departure_time, duration):
    if person_id is None or location_id is None:
        print(f"è­¦å‘Šï¼šç”±æ–¼å­˜åœ¨ç©ºå€¼ï¼Œè·³éåœç•™è¨˜éŒ„æ’å…¥ã€‚PersonID: {person_id}, LocationID: {location_id}")
        return
    query = """
    INSERT INTO StayRecord (PersonID, LocationID, ArrivalTime, DepartureTime, Duration)
    VALUES (?, ?, ?, ?, ?)
    """
    duration_str = format(duration, '.10f').rstrip('0').rstrip('.')
    cursor.execute(query, (person_id, location_id, arrival_time, departure_time, duration_str))
    conn.commit()

def insert_traffic_stats(location_id, start_time, end_time, person_count, average_duration, occupancy_rate):
    if location_id is None:
        print(f"è­¦å‘Šï¼šç”±æ–¼å­˜åœ¨ç©ºå€¼ï¼Œè·³é TrafficStats æ’å…¥ã€‚LocationID: {location_id}")
        return
    query = """
    INSERT INTO TrafficStats (LocationID, StartTime, EndTime, PersonCount, AverageDuration, OccupancyRate)
    VALUES (?, ?, ?, ?, ?, ?)
    """
    average_duration_str = format(average_duration, '.10f').rstrip('0').rstrip('.')
    cursor.execute(query, (location_id, start_time, end_time, person_count, average_duration_str, occupancy_rate))
    conn.commit()

def insert_congestion_record(location_id, start_time, end_time, average_occupancy_rate):
    if location_id is None:
        print(f"è­¦å‘Šï¼šç”±æ–¼å­˜åœ¨ç©ºå€¼ï¼Œè·³é CongestionRecord æ’å…¥ã€‚LocationID: {location_id}")
        return
    query = """
    INSERT INTO CongestionRecord (LocationID, StartTime, EndTime, AverageOccupancyRate)
    VALUES (?, ?, ?, ?)
    """
    cursor.execute(query, (location_id, start_time, end_time, average_occupancy_rate))
    conn.commit()

def insert_comfort_record(location_id, start_time, end_time, average_occupancy_rate):
    if location_id is None:
        print(f"è­¦å‘Šï¼šç”±æ–¼å­˜åœ¨ç©ºå€¼ï¼Œè·³é ComfortRecord æ’å…¥ã€‚LocationID: {location_id}")
        return
    query = """
    INSERT INTO ComfortRecord (LocationID, StartTime, EndTime, AverageOccupancyRate)
    VALUES (?, ?, ?, ?)
    """
    cursor.execute(query, (location_id, start_time, end_time, average_occupancy_rate))
    conn.commit()

def compute_color_for_labels(label):
    """
    ç°¡å–®å‡½æ•¸ï¼Œæ ¹æ“šé¡åˆ¥å›ºå®šç”Ÿæˆé¡è‰²ã€‚
    """
    color = [int((p * (label ** 2 - label + 1)) % 255) for p in palette]
    return tuple(color)

def draw_boxes(img, bbox, names, identities=None, active_objects=None, offset=(0, 0)):
    """
    ç¹ªè£½æª¢æ¸¬æ¡†ã€æ¨¡ç³Šæ¡†å…§å…§å®¹ï¼Œä»¥åŠåœ¨æ¯å€‹æ¡†çš„å³ä¸Šè§’é¡¯ç¤º ID å’Œæ»¯ç•™æ™‚é–“ã€‚
    """
    height, width, _ = img.shape
    text_info = []  # å„²å­˜æ¯å€‹æ¡†çš„æ–‡å­—åŠå…¶ä½ç½®

    for key in list(data_deque):
        if identities is not None and key not in identities:
            data_deque.pop(key)

    for i, box in enumerate(bbox):
        x1, y1, x2, y2 = [int(coord) for coord in box]
        x1 += offset[0]
        x2 += offset[0]
        y1 += offset[1]
        y2 += offset[1]

        # ç¢ºä¿åº§æ¨™åœ¨åœ–åƒç¯„åœå…§
        x1 = max(0, x1)
        y1 = max(0, y1)
        x2 = min(x2, img.shape[1])
        y2 = min(y2, img.shape[0])

        # å°äººçš„é‚Šç•Œæ¡†å…§å®¹é€²è¡Œæ¨¡ç³Š
        person_roi = img[y1:y2, x1:x2]
        person_roi = cv2.GaussianBlur(person_roi, (99, 99), 30)
        img[y1:y2, x1:x2] = person_roi

        # ç¹ªè£½æª¢æ¸¬æ¡†
        color = compute_color_for_labels(int(identities[i])) if identities is not None else (255, 0, 0)
        cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)

        # æ”¶é›†æ–‡å­—ä¿¡æ¯åŠå…¶ä½ç½®
        if identities is not None:
            identity = int(identities[i])
            if identity in active_objects:
                arrival_time = active_objects[identity]['arrival_time']
                duration = datetime.now() - arrival_time
                duration_minutes = round(duration.total_seconds() / 60.0, 2)
            else:
                duration_minutes = 0.0
            text = f"ID: {identity}, æ»¯ç•™: {duration_minutes} min"
            text_position = (x2, y1)  # æ¡†çš„å³ä¸Šè§’
            text_info.append((text, text_position, color))

    # ä½¿ç”¨ PIL ä¾†ç¹ªè£½ä¸­æ–‡æ–‡å­—
    im_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(im_pil)

    # è¨­å®šå­—é«”ï¼ˆè«‹ç¢ºä¿å­—é«”æ–‡ä»¶å­˜åœ¨æˆ–æ›¿æ›ç‚ºæ‚¨ç³»çµ±ä¸­çš„ä¸­æ–‡å­—é«”ï¼‰
    font_path = "C:/Windows/Fonts/simsun.ttc"  # æ‚¨å¯ä»¥æ ¹æ“šéœ€è¦æ›´æ”¹æ­¤è·¯å¾‘
    try:
        font = ImageFont.truetype(font_path, 20)
    except IOError:
        print(f"å­—é«”æ–‡ä»¶ {font_path} ä¸å­˜åœ¨ã€‚è«‹ç¢ºä¿å­—é«”æ–‡ä»¶å­˜åœ¨æˆ–æ›´æ”¹ font_path ç‚ºæœ‰æ•ˆè·¯å¾‘ã€‚")
        font = ImageFont.load_default()

    for text, position, color in text_info:
        # èª¿æ•´æ–‡å­—ä½ç½®ï¼Œé¿å…è¶…å‡ºåœ–åƒç¯„åœ
        text_bbox = font.getbbox(text)
        text_width = text_bbox[2] - text_bbox[0]
        text_height = text_bbox[3] - text_bbox[1]
        x, y = position
        if x + text_width > width:
            x = width - text_width
        if y - text_height < 0:
            y = text_height
        draw.text((x, y - text_height), text, font=font, fill=(255, 255, 255))  # ç™½è‰²æ–‡å­—

    # è½‰å› OpenCV åœ–åƒ
    img = cv2.cvtColor(np.array(im_pil), cv2.COLOR_RGB2BGR)

    return img

def detect(save_img=False):
    global location_id, spatial_density, limit_the_number_of_people, congestion_threshold, frame_count, fps, location_name

    source, weights, view_img, save_txt, imgsz, trace = opt.source, opt.weights, opt.view_img, opt.save_txt, opt.img_size, not opt.no_trace

    save_img = not opt.nosave and not source.endswith('.txt')

    # åˆå§‹åŒ–ä¸€äº›è®Šæ•¸
    person_count = 0

    # ç›®éŒ„
    save_dir = Path(increment_path(Path(opt.project) / opt.name, exist_ok=opt.exist_ok))
    (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)

    # è¨­ç½® FFMPEG ä½å»¶é²é¸é …
    os.environ["OPENCV_FFMPEG_CAPTURE_OPTIONS"] = "rtsp_transport;udp"

    # åˆå§‹åŒ–
    set_logging()
    device = select_device(opt.device)
    half = device.type != 'cpu'

    # åŠ è¼‰æ¨¡å‹
    model = attempt_load(weights, map_location=device)
    stride = int(model.stride.max())
    imgsz = check_img_size(imgsz, s=stride)

    if trace:
        model = TracedModel(model, device, opt.img_size)

    if half:
        model.half()

    classify = False
    if classify:
        modelc = load_classifier(name='resnet101', n=2)
        modelc.load_state_dict(
            torch.load('weights/resnet101.pt', map_location=device, weights_only=True)['model']
        ).to(device).eval()


    vid_path, vid_writer = None, None
    view_img = check_imshow()
    cudnn.benchmark = True

    # ä¿®æ”¹ LoadStreams ä»¥è¨­ç½®ç·©è¡å€å¤§å°
    dataset = LoadStreams(source, img_size=imgsz, stride=stride)

    names = model.module.names if hasattr(model, 'module') else model.names

    if device.type != 'cpu':
        model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))

    old_img_w = old_img_h = imgsz
    old_img_b = 1

    t0 = time.time()

    cfg_deep = get_config()
    cfg_deep.merge_from_file("deep_sort_pytorch/configs/deep_sort.yaml")
    deepsort = DeepSort(cfg_deep.DEEPSORT.REID_CKPT,
                       max_dist=0.7,
                       min_confidence=0.3,
                       nms_max_overlap=cfg_deep.DEEPSORT.NMS_MAX_OVERLAP,
                       max_iou_distance=0.7,
                       max_age=50,
                       n_init=3,
                       nn_budget=cfg_deep.DEEPSORT.NN_BUDGET,
                       use_cuda=True)

    frame_count = 0
    fps = 30

    last_insert_time_60s_datetime = datetime.now()
    interval_departed_objects = []

    active_objects = {}
    max_age = deepsort.tracker.max_age

    video_writers = {}

    last_congestion_status = None
    last_congestion_notification_time = datetime.min
    congestion_notification_interval = timedelta(minutes=5)
    overstay_duration_threshold = timedelta(minutes=30)

    for path, img, im0s, vid_cap in dataset:
        start_time = time.time()  # é–‹å§‹æ™‚é–“

        if vid_cap:
            fps = vid_cap.get(cv2.CAP_PROP_FPS)
            if fps == 0 or fps is None:
                fps = 24
        else:
            fps = 24

        # æ¯å¹€é‡æ–°åˆå§‹åŒ– person_count
        person_count = 0

        img = torch.from_numpy(img).to(device)
        img = img.half() if half else img.float()
        img /= 255.0
        if img.ndimension() == 3:
            img = img.unsqueeze(0)

        if device.type != 'cpu' and (old_img_b != img.shape[0] or old_img_h != img.shape[2] or old_img_w != img.shape[3]):
            old_img_b = img.shape[0]
            old_img_h = img.shape[2]
            old_img_w = img.shape[3]
            for i in range(3):
                model(img, augment=opt.augment)[0]

        t1 = time_synchronized()
        with torch.no_grad():
            pred = model(img, augment=opt.augment)[0]
        t2 = time_synchronized()

        pred = non_max_suppression(pred, opt.conf_thres, opt.iou_thres, classes=opt.classes, agnostic=opt.agnostic_nms)
        t3 = time_synchronized()

        inference_time = t2 - t1
        nms_time = t3 - t2

        for i, det in enumerate(pred):
            p, s, im0, frame = dataset.sources[i], '%g: ' % i, im0s[i].copy(), dataset.count

            p = Path(p)

            if save_img:
                if p not in video_writers:
                    width = im0.shape[1]
                    height = im0.shape[0]
                    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
                    output_path = save_dir / f"{p.stem}_{i}.mp4"
                    video_writers[p] = cv2.VideoWriter(str(output_path), fourcc, fps, (width, height))
                    print(f"åˆå§‹åŒ– VideoWriterï¼Œè¼¸å‡ºè·¯å¾‘ï¼š{output_path}")

            if len(det):
                det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()

                for c in det[:, -1].unique():
                    n = (det[:, -1] == c).sum()
                    s += f"{n} {names[int(c)]}{'s' * (n > 1)}, "

                xywhs = xyxy2xywh(det[:, 0:4])
                confs = det[:, 4]
                clss = det[:, 5]

                outputs = deepsort.update(xywhs.cpu(), confs.cpu(), clss.cpu(), im0)

                current_ids = set()
                for track in deepsort.tracker.tracks:
                    if not track.is_confirmed():
                        continue
                    id = track.track_id
                    current_ids.add(id)
                    if id not in active_objects:
                        person_id = create_person(int(id))
                        arrival_time = datetime.now()
                        active_objects[id] = {
                            'arrival_time': arrival_time,
                            'person_id': person_id,
                            'missing_frames': 0,
                            'notified_over_30': False
                        }
                    else:
                        active_objects[id]['missing_frames'] = 0

                ids_to_remove = []
                for id in list(active_objects.keys()):
                    if id not in current_ids:
                        active_objects[id]['missing_frames'] += 1
                        if active_objects[id]['missing_frames'] >= max_age:
                            data = active_objects[id]
                            departure_time = datetime.now()
                            duration_timedelta = departure_time - data['arrival_time']
                            duration_minutes = duration_timedelta.total_seconds() / 60.0
                            person_id = data['person_id']
                            arrival_time = data['arrival_time']
                            insert_stay_record(person_id, location_id, arrival_time, departure_time, duration_minutes)
                            interval_departed_objects.append({
                                'duration': duration_minutes,
                                'person_id': person_id
                            })
                            ids_to_remove.append(id)
                for id in ids_to_remove:
                    del active_objects[id]

                if len(outputs) > 0:
                    bbox_xyxy = outputs[:, :4]
                    identities = outputs[:, 4]
                    # Debug: print identities
                    print(f"Detected identities: {identities}")
                    im0 = draw_boxes(im0, bbox_xyxy, names, identities, active_objects)

            # æ›´æ–° person_count
            person_count = len(active_objects)

            # è¨ˆç®—ä½”ç”¨ç‡
            occupancy_rate = (person_count / (spatial_density * limit_the_number_of_people)) * 100 if spatial_density * limit_the_number_of_people != 0 else 0
            occupancy_rate = min(round(occupancy_rate, 2), 100)

            # ç¢ºå®šç‹€æ…‹å’Œé¡è‰²
            if occupancy_rate >= 100:
                status = "å£…å¡"
                status_color = (0, 0, 255)
            elif occupancy_rate >= 80:
                status = "å³å°‡å£…å¡"
                status_color = (0, 165, 255)
            elif occupancy_rate >= 60:
                status = "æ­£å¸¸"
                status_color = (0, 255, 0)
            else:
                status = "èˆ’é©"
                status_color = (255, 0, 0)

            # åœ¨å·¦ä¸Šè§’é¡¯ç¤ºç‹€æ…‹å’Œäººæ•¸ï¼Œå­—é«”ç¨å¤§
            end_time = time.time()
            total_time = end_time - start_time
            fps_display = 1 / total_time if total_time > 0 else 0

            # ç§»é™¤ç•«é¢ä¸Šçš„æ¨è«–æ™‚é–“å’Œ FPS é¡¯ç¤ºï¼Œæ”¹ç‚ºå¾Œå°è¼¸å‡º
            print(f"Inference Time: {inference_time*1000:.1f} ms, NMS Time: {nms_time*1000:.1f} ms, FPS: {fps_display:.1f}")
            print(f"Person Count: {person_count}")

            # ä½¿ç”¨ PIL ä¾†ç¹ªè£½ä¸­æ–‡æ–‡å­—
            # Convert OpenCV image (im0) to PIL Image
            im_pil = Image.fromarray(cv2.cvtColor(im0, cv2.COLOR_BGR2RGB))
            draw_pil = ImageDraw.Draw(im_pil)

            # Set font (You need to have a font that supports Chinese characters)
            font_path = "C:/Windows/Fonts/simsun.ttc"  # è«‹ç¢ºä¿å­—é«”æ–‡ä»¶å­˜åœ¨æˆ–æ›¿æ›ç‚ºæ‚¨ç³»çµ±ä¸­çš„ä¸­æ–‡å­—é«”
            try:
                font_status = ImageFont.truetype(font_path, 30)
                font_count = ImageFont.truetype(font_path, 30)
            except IOError:
                print(f"å­—é«”æ–‡ä»¶ {font_path} ä¸å­˜åœ¨ã€‚è«‹ç¢ºä¿å­—é«”æ–‡ä»¶å­˜åœ¨æˆ–æ›´æ”¹ font_path ç‚ºæœ‰æ•ˆè·¯å¾‘ã€‚")
                font_status = ImageFont.load_default()
                font_count = ImageFont.load_default()

            # Convert colors from BGR to RGB
            status_color_rgb = (status_color[2], status_color[1], status_color[0])
            white_color_rgb = (255, 255, 255)

            # Draw status and person count
            draw_pil.text((10, 10), f"ç‹€æ…‹: {status}", font=font_status, fill=status_color_rgb)
            draw_pil.text((10, 50), f"äººæ•¸: {person_count}", font=font_count, fill=white_color_rgb)

            # Convert back to OpenCV image
            im0 = cv2.cvtColor(np.array(im_pil), cv2.COLOR_RGB2BGR)

            if save_img and p in video_writers:
                video_writers[p].write(im0)

            if (datetime.now() - last_insert_time_60s_datetime) >= timedelta(seconds=60):
                current_time = datetime.now()
                start_time_db = last_insert_time_60s_datetime
                end_time_db = current_time

                total_duration = sum(obj['duration'] for obj in interval_departed_objects)
                total_person_count = len(interval_departed_objects)

                if total_person_count > 0:
                    average_duration = total_duration / total_person_count
                else:
                    average_duration = 0

                occupancy_rate = (person_count / (spatial_density * limit_the_number_of_people)) * 100 if spatial_density * limit_the_number_of_people != 0 else 0
                occupancy_rate = min(round(occupancy_rate, 2), 100)

                insert_traffic_stats(location_id, start_time_db, end_time_db, person_count, average_duration, occupancy_rate)

                if occupancy_rate >= 100:
                    average_occupancy = occupancy_rate
                    insert_congestion_record(location_id, start_time_db, end_time_db, average_occupancy)
                if occupancy_rate < 60:
                    average_occupancy = occupancy_rate
                    insert_comfort_record(location_id, start_time_db, end_time_db, average_occupancy)

                interval_departed_objects.clear()
                last_insert_time_60s_datetime = current_time

            current_time = datetime.now()
            if status in ["å³å°‡å£…å¡", "å£…å¡"]:
                if (status != last_congestion_status) or (current_time - last_congestion_notification_time > congestion_notification_interval):
                    message = (
                        "\n\n"
                        f"âš ï¸ è­¦ç¤ºé€šçŸ¥ï¼š{location_name}ç¾å ´äººæ•¸é”åˆ°{status}ç‹€æ…‹ï¼ âš ï¸\n\n"
                        "ğŸ“Š ç¾æ³ï¼š\n"
                        f"- ç•¶å‰äººæ•¸ï¼š{person_count}äºº\n"
                        f"- å»ºè­°å®¹ç´äººæ•¸ï¼š{int(congestion_threshold)}äºº\n\n"
                        "ğŸ› ï¸ è«‹ç«‹å³æ¡å–ä»¥ä¸‹æªæ–½ï¼š\n"
                        "-----------\n"
                        "#### 1. ç¾å ´ç›£æ¸¬èˆ‡é€šå ±\n"
                        "1. **æ«ƒæª¯äººå“¡è§€å¯Ÿå£…å¡**\n"
                        "   - æ«ƒæª¯äººå“¡æ³¨æ„åˆ°ç­‰å¾…æ‚£è€…éå¤šæˆ–æ’éšŠæ™‚é–“æ˜é¡¯å»¶é•·ã€‚\n"
                        "   - äººå“¡åˆæ­¥åˆ¤æ–·æ˜¯å¦é”åˆ°å£…å¡æ¨™æº–ã€‚\n\n"
                        "2. **é€šçŸ¥ç®¡ç†éƒ¨é–€**\n"
                        "   - æ«ƒæª¯äººå“¡é€šéé›»è©±æˆ–å…§éƒ¨å³æ™‚é€šè¨Šå·¥å…·é€šçŸ¥è³‡è¨Šå®¤ï¼Œèªªæ˜å£…å¡ç‹€æ³ã€‚\n"
                        "   - å¿…è¦æ™‚ï¼ŒåŒæ™‚é€šçŸ¥è­·ç†ç«™æˆ–é™¢å‹™è™•ï¼Œè«‹æ±‚ç¾å ´æ”¯æ´ã€‚\n\n"
                        "#### 3. èª¿åº¦æ”¯æ´äººå“¡\n"
                        "1. **é€šçŸ¥å¢æ´äººå“¡**\n"
                        "   - è³‡è¨Šå®¤å‘é™¢å…§é å‚™äººå“¡æˆ–å…¶ä»–ç§‘å®¤è«‹æ±‚æ”¯æ´ï¼Œå¢æ´¾äººå“¡åˆ°å¤§å»³ã€‚\n"
                        "   - æ«ƒæª¯æœå‹™äººå“¡æ ¹æ“šè³‡è¨Šå®¤æŒ‡ç¤ºï¼Œèª¿æ•´åˆ†å·¥æ‡‰å°ã€‚\n\n"
                        "2. **å¯¦æ–½åˆ†æµæªæ–½**\n"
                        "   - å®‰æ’è­·ç†äººå“¡æˆ–å¿—é¡˜è€…ï¼Œå¼•å°æ‚£è€…è‡³è¼ƒç©ºé–’çš„æ«ƒæª¯æˆ–è‡ªåŠ©æœå‹™å€ã€‚\n"
                        "   - å¿…è¦æ™‚é–‹æ”¾è‡¨æ™‚æœå‹™çª—å£ã€‚\n\n"
                        "#### 4. æŒçºŒç›£æ§èˆ‡æ›´æ–°\n"
                        "1. **å‹•æ…‹ç›£æ§**\n"
                        "   - ç¾å ´æ”¯æ´äººå“¡æŒçºŒé—œæ³¨å£…å¡ç‹€æ³ï¼Œå¯¦æ™‚æ›´æ–°è³‡è¨Šå®¤ã€‚\n"
                        "   - è³‡è¨Šå®¤æ ¹æ“šæœ€æ–°æƒ…æ³ï¼Œæä¾›é€²ä¸€æ­¥çš„åˆ†æµå»ºè­°ã€‚\n\n"
                        "2. **äº‹ä»¶çµæŸ**\n"
                        "   - å£…å¡è§£é™¤å¾Œï¼Œç¾å ´äººå“¡èˆ‡è³‡è¨Šå®¤è¨˜éŒ„è™•ç†éç¨‹ï¼Œå½¢æˆå ±å‘Šã€‚\n\n"
                        "ğŸ”— æŸ¥çœ‹å„€è¡¨æ¿è©³æƒ…ï¼š\n"
                        f"{dashboard_url}"
                    )
                    status_code, response_text = send_line_notify(message, access_token)
                    if status_code == 200:
                        print(f"å·²ç™¼é€{status}ç‹€æ…‹é€šçŸ¥")
                        last_congestion_status = status
                        last_congestion_notification_time = current_time
                    else:
                        print(f"ç™¼é€é€šçŸ¥å¤±æ•—: {response_text}")

            for id in active_objects:
                data = active_objects[id]
                current_time = datetime.now()
                duration = current_time - data['arrival_time']
                if duration >= overstay_duration_threshold:
                    if not data.get('notified_over_30', False):
                        message = (
                            "\n\n"
                            f"âš ï¸ æ»¯ç•™é€šçŸ¥ï¼šIDç‚º {id} çš„äººå“¡å·²åœ¨ {location_name} æ»¯ç•™è¶…é30åˆ†é˜ï¼ âš ï¸\n\n"
                            "ğŸ› ï¸ è«‹ç«‹å³æ¡å–ä»¥ä¸‹æªæ–½ï¼š\n"
                            "-----------\n"
                            "#### 1. æ»¯ç•™æª¢æ¸¬èˆ‡é€šå ±\n"
                            "1. **æ«ƒæª¯äººå“¡è§€å¯Ÿæ»¯ç•™**\n"
                            "   - æ«ƒæª¯äººå“¡æ³¨æ„åˆ°æ»¯ç•™æ‚£è€…ã€‚\n"
                            "   - äººå“¡åˆæ­¥åˆ¤æ–·æ»¯ç•™åŸå› åŠå½±éŸ¿ã€‚\n\n"
                            "2. **é€šçŸ¥ç®¡ç†éƒ¨é–€**\n"
                            "   - æ«ƒæª¯äººå“¡é€šéé›»è©±æˆ–å…§éƒ¨å³æ™‚é€šè¨Šå·¥å…·é€šçŸ¥è³‡è¨Šå®¤ï¼Œèªªæ˜æ»¯ç•™ç‹€æ³ã€‚\n"
                            "   - å¿…è¦æ™‚ï¼ŒåŒæ™‚é€šçŸ¥è­·ç†ç«™æˆ–é™¢å‹™è™•ï¼Œè«‹æ±‚ç¾å ´æ”¯æ´ã€‚\n\n"
                            "#### 2. èª¿æŸ¥èˆ‡è©•ä¼°\n"
                            "1. **èª¿æŸ¥æ»¯ç•™åŸå› **\n"
                            "   - è³‡è¨Šå®¤äººå“¡æ ¹æ“šå ±å‘Šé€²è¡Œèª¿æŸ¥ï¼Œäº†è§£æ»¯ç•™åŸå› ã€‚\n\n"
                            "2. **è©•ä¼°å½±éŸ¿**\n"
                            "   - è©•ä¼°æ»¯ç•™å°ç¾å ´ç§©åºå’Œæœå‹™æ•ˆç‡çš„å½±éŸ¿ã€‚\n\n"
                            "#### 3. èª¿åº¦æ”¯æ´äººå“¡\n"
                            "1. **é€šçŸ¥å¢æ´äººå“¡**\n"
                            "   - è³‡è¨Šå®¤å‘é™¢å…§é å‚™äººå“¡æˆ–å…¶ä»–ç§‘å®¤è«‹æ±‚æ”¯æ´ï¼Œå¢æ´¾äººå“¡åˆ°å¤§å»³ã€‚\n"
                            "   - æ«ƒæª¯æœå‹™äººå“¡æ ¹æ“šè³‡è¨Šå®¤æŒ‡ç¤ºï¼Œèª¿æ•´åˆ†å·¥æ‡‰å°ã€‚\n\n"
                            "2. **å¯¦æ–½è™•ç†æªæ–½**\n"
                            "   - æ´¾é£è­·ç†äººå“¡æˆ–å¿—é¡˜è€…å”åŠ©æ»¯ç•™æ‚£è€…ã€‚\n"
                            "   - å¿…è¦æ™‚ï¼Œæä¾›é¡å¤–çš„å”åŠ©æœå‹™ã€‚\n\n"
                            "#### 4. æŒçºŒç›£æ§èˆ‡æ›´æ–°\n"
                            "1. **å‹•æ…‹ç›£æ§**\n"
                            "   - ç¾å ´æ”¯æ´äººå“¡æŒçºŒé—œæ³¨æ»¯ç•™ç‹€æ³ï¼Œå¯¦æ™‚æ›´æ–°è³‡è¨Šå®¤ã€‚\n"
                            "   - è³‡è¨Šå®¤æ ¹æ“šæœ€æ–°æƒ…æ³ï¼Œæä¾›é€²ä¸€æ­¥çš„å”åŠ©å»ºè­°ã€‚\n\n"
                            "2. **äº‹ä»¶çµæŸ**\n"
                            "   - æ»¯ç•™è§£é™¤å¾Œï¼Œç¾å ´äººå“¡èˆ‡è³‡è¨Šå®¤è¨˜éŒ„è™•ç†éç¨‹ï¼Œå½¢æˆå ±å‘Šã€‚\n\n"
                            "ğŸ”— æŸ¥çœ‹å„€è¡¨æ¿è©³æƒ…ï¼š\n"
                            f"{dashboard_url}"
                        )
                        status_code, response_text = send_line_notify(message, access_token)
                        if status_code == 200:
                            print(f"å·²ç™¼é€ID {id} çš„æ»¯ç•™é€šçŸ¥")
                            data['notified_over_30'] = True
                        else:
                            print(f"ç™¼é€é€šçŸ¥å¤±æ•—: {response_text}")

        # åªé¡¯ç¤ºç¬¬ä¸€å€‹æµï¼ˆæˆ–æ‚¨é¸æ“‡çš„æµï¼‰
        if view_img:
            window_name = f"Stream {i} - {p.name}"
            cv2.imshow(window_name, im0)
            cv2.waitKey(1)

        frame_count += 1

    print(f'å®Œæˆã€‚ ({time.time() - t0:.3f} ç§’)')

    if save_img:
        for writer in video_writers.values():
            writer.release()

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--weights', nargs='+', type=str, default='yolov7.pt', help='æ¨¡å‹è·¯å¾‘')
    parser.add_argument('--source', type=str, default='', help='ä¾†æº')
    parser.add_argument('--img-size', type=int, default=480, help='æ¨è«–åœ–åƒå¤§å°ï¼ˆåƒç´ ï¼‰')  # æ¸›å°‘åœ–åƒå¤§å°ä»¥åŠ å¿«é€Ÿåº¦
    parser.add_argument('--conf-thres', type=float, default=0.25, help='ç‰©é«”ç½®ä¿¡é–€æª»')
    parser.add_argument('--iou-thres', type=float, default=0.45, help='NMS çš„ IOU é–€æª»')
    parser.add_argument('--device', default='0', help='cuda è¨­å‚™ï¼Œä¾‹å¦‚ 0 æˆ– 0,1,2,3 æˆ– cpu')
    parser.add_argument('--view-img', action='store_true', help='é¡¯ç¤ºçµæœ')
    parser.add_argument('--save-txt', action='store_true', help='å°‡çµæœä¿å­˜ç‚º *.txt')
    parser.add_argument('--save-conf', action='store_true', help='ä¿å­˜ç½®ä¿¡åº¦æ–¼ --save-txt æ¨™ç±¤')
    parser.add_argument('--nosave', action='store_true', help='ä¸ä¿å­˜åœ–åƒ/è¦–é »')
    parser.add_argument('--classes', nargs='+', type=int, default=[0], help='æŒ‰é¡åˆ¥ç¯©é¸ï¼š--class 0, æˆ– --class 0 2 3')
    parser.add_argument('--agnostic-nms', action='store_true', help='é¡åˆ¥ç„¡é—œçš„ NMS')
    parser.add_argument('--augment', action='store_true', help='å¢å¼·æ¨è«–')
    parser.add_argument('--update', action='store_true', help='æ›´æ–°æ‰€æœ‰æ¨¡å‹')
    parser.add_argument('--project', default='runs/detect', help='ä¿å­˜çµæœè‡³é …ç›®/åç¨±')
    parser.add_argument('--name', default='exp', help='ä¿å­˜çµæœè‡³é …ç›®/åç¨±')
    parser.add_argument('--exist-ok', action='store_true', help='å…è¨±å·²æœ‰çš„é …ç›®/åç¨±ï¼Œä¸éå¢')
    parser.add_argument('--no-trace', action='store_true', help='ä¸è¿½è¹¤æ¨¡å‹')
    # æ·»åŠ å‘½ä»¤è¡Œåƒæ•¸ï¼Œç”¨æ–¼é¸æ“‡è¦è™•ç†çš„æ”å½±æ©Ÿç·¨è™Ÿ
    parser.add_argument('--camera-index', type=int, default=-1, help='è¦è™•ç†çš„æ”å½±æ©Ÿç·¨è™Ÿï¼Œ-1è¡¨ç¤ºé¡¯ç¤ºæ‰€æœ‰æ”å½±æ©Ÿ')
    opt = parser.parse_args()
    print(opt)

    # è®“ç”¨æˆ¶é¸æ“‡ä½ç½®
    print("è«‹é¸æ“‡ä¸€å€‹ä½ç½®ï¼š")
    print("-----------")
    print("1. é†«é™¢å¤§å»³å·¦åŠéƒ¨")
    print("2. é†«é™¢å¤§å»³å³åŠéƒ¨")
    print("3. é†«é™¢å’–å•¡å»³ A å€")
    print("4. Mlab-Test-1")
    print("5. Mlab-Test-2")
    print("-----------")

    while True:
        try:
            location_choice = int(input("è«‹è¼¸å…¥ä½ç½®ç·¨è™Ÿ (1-5): "))
            if 1 <= location_choice <= 5:
                location_id = location_choice
                break
            else:
                print("è«‹è¼¸å…¥æœ‰æ•ˆçš„ä½ç½®ç·¨è™Ÿ (1-5)ã€‚")
        except ValueError:
            print("è«‹è¼¸å…¥æœ‰æ•ˆçš„æ•¸å­—ã€‚")

    # ç²å–é¸æ“‡çš„ä½ç½®ä¿¡æ¯
    location_name, spatial_density = get_location_info(location_id)
    print(f"å·²é¸æ“‡ä½ç½®ï¼š{location_name}ï¼Œç©ºé–“å¤§å°ï¼š{spatial_density} å¹³æ–¹å…¬å°º")

    # æ·»åŠ åˆ†éš”ç·š
    print("-----------")

    # è©¢å•ç”¨æˆ¶æ˜¯å¦è¦èª¿æ•´é»˜èªå®¹ç´äººæ•¸
    question = str(input("è«‹å•æ˜¯å¦éœ€è¦è®Šæ›´æ¯å¹³æ–¹ç±³å®¹ç´äººæ•¸åƒæ•¸(éœ€è¦è®Šæ›´è«‹è¼¸å…¥1ï¼Œç„¡é ˆè®Šæ›´è«‹è¼¸å…¥0):"))
    while True:
        if question == '1':
            while True:
                try:
                    limit_the_number_of_people = int(input("è«‹è¼¸å…¥æ¯å¹³æ–¹ç±³å®¹ç´äººæ•¸(é»˜èªå€¼ç‚º:3):"))
                    if limit_the_number_of_people > 0:
                        break
                    else:
                        print("è«‹å‹¿è¼¸å…¥ç„¡æ•ˆåƒæ•¸!!")
                except ValueError:
                    print("æ‚¨è¼¸å…¥çš„ä¸æ˜¯æœ‰æ•ˆçš„æ•¸å­—ï¼Œè«‹é‡æ–°è¼¸å…¥ã€‚")
            break
        elif question == '0':
            limit_the_number_of_people = 3
            break
        else:
            print("è«‹è¼¸å…¥æ­£ç¢ºæ•¸å€¼")
            question = str(input("è«‹å•æ˜¯å¦éœ€è¦è®Šæ›´æ¯å¹³æ–¹ç±³å®¹ç´äººæ•¸åƒæ•¸(éœ€è¦è®Šæ›´è«‹è¼¸å…¥1ï¼Œç„¡é ˆè®Šæ›´è«‹è¼¸å…¥0):"))

    # è¨ˆç®—äººæµå£…å¡ç•Œé™
    congestion_threshold = spatial_density * limit_the_number_of_people
    comfort_threshold = round(congestion_threshold * 0.4, 3)
    normal_threshold = round(congestion_threshold * 0.6, 3)
    near_congestion_threshold = round(congestion_threshold * 0.8, 3)

    print(f"äººæµå£…å¡ç•Œé™: {congestion_threshold}")
    print(f"å³å°‡å£…å¡ç•Œé™: {near_congestion_threshold}")
    print(f"äººæµèˆ’é©ç•Œé™: {comfort_threshold}")
    print(f"äººæµæ­£å¸¸ç•Œé™: {normal_threshold}")

    # æ·»åŠ åˆ†éš”ç·š
    print("-----------")

    # æ·»åŠ  RTSP ä¾†æºï¼Œè«‹è‡ªè¡Œå¡«å¯«ç”¨æˆ¶åã€å¯†ç¢¼å’Œ IP åœ°å€ï¼Œä¸¦è¨­ç½®ç·©è¡å€åƒæ•¸
    rtsp_url_1 = "rtsp://admin:Mlab03+-@192.168.0.118:554/cam/realmonitor?channel=1&subtype=0&buffer_size=1&fps=30"
    rtsp_url_2 = "rtsp://admin:Mlab03+-@192.168.0.118:554/cam/realmonitor?channel=2&subtype=0&buffer_size=1&fps=30"

    # å¦‚æœæœªåœ¨å‘½ä»¤è¡ŒæŒ‡å®š sourceï¼Œå‰‡ä½¿ç”¨é è¨­çš„ RTSP æµ
    if not opt.source:
        rtsp_urls = [rtsp_url_1, rtsp_url_2]
        camera_names = ["çƒå½¢æ”å½±æ©Ÿ", "æ§å‹æ”å½±æ©Ÿ"]
        # å¦‚æœç”¨æˆ¶æŒ‡å®šäº†æ”å½±æ©Ÿç·¨è™Ÿï¼Œå‰‡åªä½¿ç”¨å°æ‡‰çš„ RTSP æµ
        if opt.camera_index >= 0 and opt.camera_index < len(rtsp_urls):
            opt.source = rtsp_urls[opt.camera_index]
        else:
            # è®“ç”¨æˆ¶é¸æ“‡è¦è™•ç†çš„æ”å½±æ©Ÿ
            print("è«‹é¸æ“‡è¦è™•ç†çš„æ”å½±æ©Ÿï¼š")
            print("-----------")
            for idx, name in enumerate(camera_names):
                print(f"{idx}. {name}")
            print("-----------")
            while True:
                try:
                    camera_choice = int(input(f"è«‹è¼¸å…¥æ”å½±æ©Ÿç·¨è™Ÿ (0-{len(rtsp_urls)-1}): "))
                    if 0 <= camera_choice < len(rtsp_urls):
                        opt.source = rtsp_urls[camera_choice]
                        break
                    else:
                        print(f"è«‹è¼¸å…¥æœ‰æ•ˆçš„æ”å½±æ©Ÿç·¨è™Ÿ (0-{len(rtsp_urls)-1})ã€‚")
                except ValueError:
                    print("è«‹è¼¸å…¥æœ‰æ•ˆçš„æ•¸å­—ã€‚")
    else:
        # å¦‚æœå‘½ä»¤è¡ŒæŒ‡å®šäº† sourceï¼Œå‰‡ä½¿ç”¨å‘½ä»¤è¡Œçš„å€¼
        opt.source = opt.source

    with torch.no_grad():
        if opt.update:
            for opt.weights in ['yolov7.pt']:
                detect()
                strip_optimizer(opt.weights)
        else:
            detect()
